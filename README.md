# ğŸ“ Call Center Chatbot

An AI-powered **Call Center Chatbot** using **completely open-source models** that can run on **CPU and GPU**. This chatbot handles customer inquiries, retrieves company policies, and accesses customer data efficiently.

---

## **âœ¨ Features**
âœ… Uses **fully open-source models** like **Mistral-7B-Instruct (GGUF)**  
âœ… Runs **locally** on **CPU or GPU**â€”no external APIs  
âœ… Supports **customer data lookup** via SQL database  
âœ… Fetches **company policies dynamically**  
âœ… Built with **Flask** for easy web deployment  

---

## **ğŸš€ Installation & Setup**

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/alishbalaeeq/CallCenterChatbot.git
cd CallCenterChatbot
```

### **2ï¸âƒ£ Create a Virtual Environment**
```bash
conda create --name chatbot python=3.10 -y  # For Conda users
conda activate chatbot
# OR
python -m venv chatbot  # For venv users
source chatbot/bin/activate  # macOS/Linux
chatbot\Scripts\activate  # Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set the Model Path as an Environment Variable**
Before running, define the **model path** (GGUF format):

#### **ğŸ”¹ Linux/macOS**
```bash
export MODEL_PATH="/absolute/path/to/mistral-7b-instruct-v0.1.Q4_K_M.gguf"
```

#### **ğŸ”¹ Windows (PowerShell)**
```powershell
$env:MODEL_PATH="C:\absolute\path\to\mistral-7b-instruct-v0.1.Q4_K_M.gguf"
```

---

## **ğŸ› ï¸ Running the Chatbot**
```bash
python app.py
```
The chatbot will be available at **http://127.0.0.1:5000/** in your browser.

---

## **ğŸ§  Model & LLM Setup**
This project exclusively uses **open-source AI models** to ensure **privacy, transparency, and full local control**.  
It leverages:
- **Mistral-7B-Instruct (GGUF format) from TheBloke**
- Runs via **LlamaCpp**, enabling execution on **CPU or GPU**  
- No proprietary APIsâ€”**everything runs locally**  

```python
from langchain_community.llms import LlamaCpp
import os

# Load model from environment variable
model_path = os.getenv("MODEL_PATH")

llm = LlamaCpp(
    model_path=model_path,
    temperature=0.1,
    max_new_tokens=256,
    context_window=3900,
    n_ctx=2048,
    n_gpu_layers=50,  # Set to 0 for CPU-only
    verbose=True
)
```

### **âš¡ Want to Run on CPU?**
If you **don't have a GPU**, simply set:
```python
n_gpu_layers = 0  # Forces LlamaCpp to run entirely on CPU
```
This ensures that it runs smoothly even on **CPU-only** machines.

---

## **ğŸ“‚ Project Structure**
```
CallCenterChatbot/
â”‚â”€â”€ files/                     # Stores database & company policies
â”‚â”€â”€ static/                    # CSS and frontend assets
â”‚â”€â”€ templates/                 # HTML templates
â”‚â”€â”€ utils/                     # Modular utility scripts
â”‚   â”œâ”€â”€ config.py              # Logging & global settings
â”‚   â”œâ”€â”€ llm_setup.py           # LLM initialization (LlamaCpp)
â”‚   â”œâ”€â”€ tools.py               # Tools for database & policy queries
â”‚â”€â”€ app.py                     # Main Flask application
â”‚â”€â”€ requirements.txt           # Dependencies list
â”‚â”€â”€ README.md                  # Youâ€™re reading it now!
```

---

## **ğŸ› ï¸ Tools & Technologies**
- **Flask** â†’ Web Framework  
- **LangChain** â†’ AI Agent Orchestration  
- **LlamaCpp** â†’ Efficient local model inference  
- **SQLite** â†’ Customer data storage  
- **Hugging Face Transformers** â†’ Model loading  

---

## **ğŸ’¡ Customization**
Want to use a different **open-source model**? Modify the **model path**:
```bash
export MODEL_PATH="/path/to/another-model.gguf"
```
Then restart the app!

---

## **ğŸ”’ Privacy & Security**
âœ… **No external API calls**â€”All processing happens **locally**  
âœ… **No data sharing**â€”Ensures **customer privacy**  
âœ… **Fully Open-Source**â€”No vendor lock-in  

---

## **ğŸ“¬ Contact & Contributions**
We welcome **contributions**! Feel free to **fork**, submit **issues**, or suggest improvements. ğŸš€  

---
ğŸ”¥ **Call Center Chatbot** â†’ AI-driven customer support using **100% open-source models**! ğŸ”¥